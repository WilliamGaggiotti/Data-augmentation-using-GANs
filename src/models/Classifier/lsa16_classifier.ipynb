{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "underlying-surname",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "international-medline",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "import handshape_datasets as hd\n",
    "from IPython import display\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import VGG16, VGG19\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Conv2D, LeakyReLU, Dropout, Flatten\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-therapy",
   "metadata": {},
   "source": [
    "### Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-heating",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "              tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "        \n",
    "print(tf.config.experimental.list_logical_devices('GPU'))\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-israeli",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "broad-working",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Loading lsa16...\n",
      "INFO:Loading default version: color\n"
     ]
    }
   ],
   "source": [
    "data = hd.load('lsa16')\n",
    "\n",
    "good_min = 40\n",
    "good_classes = []\n",
    "n_unique = len(np.unique(data[1]['y']))\n",
    "for i in range(n_unique):\n",
    "    images = data[0][np.equal(i, data[1]['y'])]\n",
    "    if len(images) >= good_min:\n",
    "        good_classes = good_classes + [i]\n",
    "        \n",
    "x = data[0][np.in1d(data[1]['y'], good_classes)]\n",
    "img_shape = x[0].shape\n",
    "\n",
    "y = data[1]['y'][np.in1d(data[1]['y'], good_classes)]\n",
    "y_dict = dict(zip(np.unique(y), range(len(np.unique(y)))))\n",
    "y = np.vectorize(y_dict.get)(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, test_size=0.2, stratify=y)\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "n_classes = len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-guarantee",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "foster-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "# Definición de las métricas F1, recall y precision utilizando Keras.\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "        precision = precision_m(y_true, y_pred)\n",
    "        recall = recall_m(y_true, y_pred)\n",
    "        return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-advisory",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "desirable-faculty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same',input_shape=[32, 32, 3]))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-brazilian",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "domestic-multiple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        4864      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                131088    \n",
      "=================================================================\n",
      "Total params: 340,880\n",
      "Trainable params: 340,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model()\n",
    "model.summary()\n",
    "model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy', f1_m, precision_m, recall_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "continuing-visibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 22.7238 - accuracy: 0.1604 - f1_m: 1.2385 - precision_m: 1.1974 - recall_m: 1.2832 - val_loss: 4.9372 - val_accuracy: 0.4750 - val_f1_m: 1.3466 - val_precision_m: 1.3285 - val_recall_m: 1.3658\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 4.6485 - accuracy: 0.5793 - f1_m: 1.1752 - precision_m: 1.1446 - recall_m: 1.2076 - val_loss: 2.6656 - val_accuracy: 0.7500 - val_f1_m: 1.1821 - val_precision_m: 1.1585 - val_recall_m: 1.2067\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 1.9602 - accuracy: 0.7904 - f1_m: 1.1032 - precision_m: 1.0697 - recall_m: 1.1392 - val_loss: 1.8934 - val_accuracy: 0.8625 - val_f1_m: 1.0738 - val_precision_m: 1.0469 - val_recall_m: 1.1023\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.8402 - accuracy: 0.8824 - f1_m: 1.0767 - precision_m: 1.0459 - recall_m: 1.1096 - val_loss: 1.6569 - val_accuracy: 0.8875 - val_f1_m: 1.0821 - val_precision_m: 1.0588 - val_recall_m: 1.1065\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.3748 - accuracy: 0.9370 - f1_m: 1.0434 - precision_m: 1.0151 - recall_m: 1.0736 - val_loss: 1.7315 - val_accuracy: 0.8625 - val_f1_m: 1.0461 - val_precision_m: 1.0195 - val_recall_m: 1.0743\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.2675 - accuracy: 0.9412 - f1_m: 1.0369 - precision_m: 1.0077 - recall_m: 1.0681 - val_loss: 1.6268 - val_accuracy: 0.8875 - val_f1_m: 1.0461 - val_precision_m: 1.0195 - val_recall_m: 1.0743\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.2069 - accuracy: 0.9643 - f1_m: 1.0188 - precision_m: 0.9849 - recall_m: 1.0554 - val_loss: 1.7381 - val_accuracy: 0.8813 - val_f1_m: 1.0803 - val_precision_m: 1.0549 - val_recall_m: 1.1072\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.1134 - accuracy: 0.9724 - f1_m: 0.9864 - precision_m: 0.9529 - recall_m: 1.0227 - val_loss: 1.6105 - val_accuracy: 0.9187 - val_f1_m: 0.9819 - val_precision_m: 0.9570 - val_recall_m: 1.0084\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.0683 - accuracy: 0.9788 - f1_m: 1.0005 - precision_m: 0.9706 - recall_m: 1.0322 - val_loss: 1.5816 - val_accuracy: 0.9250 - val_f1_m: 0.9981 - val_precision_m: 0.9727 - val_recall_m: 1.0252\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.0521 - accuracy: 0.9852 - f1_m: 0.9909 - precision_m: 0.9577 - recall_m: 1.0266 - val_loss: 1.7146 - val_accuracy: 0.8938 - val_f1_m: 1.0103 - val_precision_m: 0.9844 - val_recall_m: 1.0378\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.0911 - accuracy: 0.9782 - f1_m: 0.9829 - precision_m: 0.9548 - recall_m: 1.0136 - val_loss: 1.7528 - val_accuracy: 0.8875 - val_f1_m: 0.9941 - val_precision_m: 0.9688 - val_recall_m: 1.0210\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.0518 - accuracy: 0.9904 - f1_m: 0.9848 - precision_m: 0.9560 - recall_m: 1.0155 - val_loss: 1.6582 - val_accuracy: 0.9062 - val_f1_m: 1.0218 - val_precision_m: 0.9961 - val_recall_m: 1.0491\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.0083 - accuracy: 0.9987 - f1_m: 0.9769 - precision_m: 0.9505 - recall_m: 1.0049 - val_loss: 1.5909 - val_accuracy: 0.9125 - val_f1_m: 1.0258 - val_precision_m: 1.0000 - val_recall_m: 1.0533\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 0.0056 - accuracy: 0.9990 - f1_m: 0.9746 - precision_m: 0.9421 - recall_m: 1.0095 - val_loss: 1.5670 - val_accuracy: 0.9250 - val_f1_m: 1.0059 - val_precision_m: 0.9805 - val_recall_m: 1.0329\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.0032 - accuracy: 0.9986 - f1_m: 0.9702 - precision_m: 0.9414 - recall_m: 1.0009 - val_loss: 1.5273 - val_accuracy: 0.9187 - val_f1_m: 0.9880 - val_precision_m: 0.9647 - val_recall_m: 1.0126\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.0190 - accuracy: 0.9972 - f1_m: 0.9793 - precision_m: 0.9505 - recall_m: 1.0100 - val_loss: 1.5600 - val_accuracy: 0.9250 - val_f1_m: 0.9900 - val_precision_m: 0.9648 - val_recall_m: 1.0168\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 104ms/step - loss: 0.0120 - accuracy: 0.9940 - f1_m: 0.9723 - precision_m: 0.9414 - recall_m: 1.0053 - val_loss: 1.6111 - val_accuracy: 0.9187 - val_f1_m: 1.0100 - val_precision_m: 0.9844 - val_recall_m: 1.0371\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 103ms/step - loss: 0.0073 - accuracy: 0.9987 - f1_m: 0.9744 - precision_m: 0.9411 - recall_m: 1.0104 - val_loss: 1.6614 - val_accuracy: 0.9187 - val_f1_m: 0.9978 - val_precision_m: 0.9727 - val_recall_m: 1.0245\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.0040 - accuracy: 0.9987 - f1_m: 0.9809 - precision_m: 0.9556 - recall_m: 1.0077 - val_loss: 1.6334 - val_accuracy: 0.9250 - val_f1_m: 0.9978 - val_precision_m: 0.9727 - val_recall_m: 1.0245\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 0.0308 - accuracy: 0.9908 - f1_m: 0.9780 - precision_m: 0.9464 - recall_m: 1.0118 - val_loss: 1.6071 - val_accuracy: 0.9250 - val_f1_m: 0.9978 - val_precision_m: 0.9727 - val_recall_m: 1.0245\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    model.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-moldova",
   "metadata": {},
   "source": [
    "## Classifier with dataset augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "continuous-chile",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Loading lsa16...\n",
      "INFO:Loading default version: color\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 32, 32, 3) (640,)\n"
     ]
    }
   ],
   "source": [
    "data = hd.load('lsa16')\n",
    "\n",
    "good_min = 40\n",
    "good_classes = []\n",
    "n_unique = len(np.unique(data[1]['y']))\n",
    "for i in range(n_unique):\n",
    "    images = data[0][np.equal(i, data[1]['y'])]\n",
    "    if len(images) >= good_min:\n",
    "        good_classes = good_classes + [i]\n",
    "        \n",
    "x = data[0][np.in1d(data[1]['y'], good_classes)]\n",
    "img_shape = x[0].shape\n",
    "\n",
    "y = data[1]['y'][np.in1d(data[1]['y'], good_classes)]\n",
    "y_dict = dict(zip(np.unique(y), range(len(np.unique(y)))))\n",
    "y = np.vectorize(y_dict.get)(y)\n",
    "\n",
    "# shapes\n",
    "img_n , height, weight, chanels = x.shape\n",
    "\n",
    "#Normalization\n",
    "x = x.reshape(img_n, height, weight, chanels).astype('float32')\n",
    "x = (x - 127.5) / 127.5  # Normalize the images to [-1, 1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, test_size=0.2, stratify=y)\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "n_classes = len(classes)\n",
    "\n",
    "#x_tuple = list(zip(x_train_aug,y_train))\n",
    "#x_train_aug\n",
    "\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-longer",
   "metadata": {},
   "source": [
    "## Generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "institutional-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(int(height/4)*int(weight/4)*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((int(height/4), int(weight/4), 256)))\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "needed-ladder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16384)             1638400   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 16384)             65536     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 8, 8, 128)         819200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 16, 16, 64)        204800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 32, 32, 3)         4800      \n",
      "=================================================================\n",
      "Total params: 2,733,504\n",
      "Trainable params: 2,700,352\n",
      "Non-trainable params: 33,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "generator.summary()\n",
    "num_examples_to_generate = 15\n",
    "noise = tf.random.normal([num_examples_to_generate, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-manor",
   "metadata": {},
   "source": [
    "## Assembling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "north-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = '../GANs/results/models/Basic-GAN/lsa16-generator-class-{}/generator_class_{}_{}.h5'\n",
    "for i in range(16):\n",
    "    for j in range(3):\n",
    "        generator.load_weights(weights_path.format(i,i,j))\n",
    "        generated_image = generator(noise, training=False).numpy()\n",
    "        x_train = np.concatenate((x_train, generated_image), axis=0)\n",
    "        y_tmp = np.ones(num_examples_to_generate,)* i\n",
    "        y_train = np.concatenate((y_train,y_tmp), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "collect-january",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1360, 32, 32, 3) (1360,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "developed-zimbabwe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1360, 32, 32, 3) (1360,)\n"
     ]
    }
   ],
   "source": [
    "shuffler = np.random.permutation(x_train.shape[0])\n",
    "x_train = x_train[shuffler]\n",
    "y_train = y_train[shuffler]\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "pediatric-eleven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 64)        4864      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_40 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                131088    \n",
      "=================================================================\n",
      "Total params: 340,880\n",
      "Trainable params: 340,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model()\n",
    "model.summary()\n",
    "model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy', f1_m, precision_m, recall_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "professional-recruitment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11/11 [==============================] - 1s 99ms/step - loss: 2.3559 - accuracy: 0.2977 - f1_m: 11.4184 - precision_m: 5700729834.6667 - recall_m: 5.8362 - val_loss: 0.7118 - val_accuracy: 0.7688 - val_f1_m: 2.4525 - val_precision_m: 2.6869 - val_recall_m: 2.2558\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 1s 83ms/step - loss: 0.4629 - accuracy: 0.8709 - f1_m: 1.5477 - precision_m: 1.5751 - recall_m: 1.5231 - val_loss: 0.6737 - val_accuracy: 0.8062 - val_f1_m: 1.4950 - val_precision_m: 1.4798 - val_recall_m: 1.5108\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.3246 - accuracy: 0.9094 - f1_m: 1.2420 - precision_m: 1.2144 - recall_m: 1.2710 - val_loss: 0.4246 - val_accuracy: 0.8687 - val_f1_m: 1.3535 - val_precision_m: 1.3476 - val_recall_m: 1.3594\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.1500 - accuracy: 0.9557 - f1_m: 1.2120 - precision_m: 1.1896 - recall_m: 1.2354 - val_loss: 0.3494 - val_accuracy: 0.8875 - val_f1_m: 1.3009 - val_precision_m: 1.2852 - val_recall_m: 1.3174\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 1s 74ms/step - loss: 0.1368 - accuracy: 0.9566 - f1_m: 1.1382 - precision_m: 1.1144 - recall_m: 1.1632 - val_loss: 0.2569 - val_accuracy: 0.9250 - val_f1_m: 1.3335 - val_precision_m: 1.3278 - val_recall_m: 1.3406\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 1s 89ms/step - loss: 0.1461 - accuracy: 0.9584 - f1_m: 1.1569 - precision_m: 1.1295 - recall_m: 1.1858 - val_loss: 0.2403 - val_accuracy: 0.9250 - val_f1_m: 1.2591 - val_precision_m: 1.2393 - val_recall_m: 1.2803\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.0886 - accuracy: 0.9774 - f1_m: 1.0886 - precision_m: 1.0576 - recall_m: 1.1215 - val_loss: 0.2847 - val_accuracy: 0.9312 - val_f1_m: 1.2236 - val_precision_m: 1.2089 - val_recall_m: 1.2390\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 0.0883 - accuracy: 0.9734 - f1_m: 1.0824 - precision_m: 1.0539 - recall_m: 1.1127 - val_loss: 0.2703 - val_accuracy: 0.9000 - val_f1_m: 1.2490 - val_precision_m: 1.2327 - val_recall_m: 1.2663\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.0766 - accuracy: 0.9802 - f1_m: 1.1018 - precision_m: 1.0772 - recall_m: 1.1276 - val_loss: 0.1899 - val_accuracy: 0.9250 - val_f1_m: 1.1698 - val_precision_m: 1.1635 - val_recall_m: 1.1773\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 1s 84ms/step - loss: 0.0550 - accuracy: 0.9855 - f1_m: 1.0529 - precision_m: 1.0251 - recall_m: 1.0826 - val_loss: 0.2010 - val_accuracy: 0.9375 - val_f1_m: 1.1506 - val_precision_m: 1.1365 - val_recall_m: 1.1654\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 1s 85ms/step - loss: 0.0474 - accuracy: 0.9861 - f1_m: 1.0318 - precision_m: 0.9997 - recall_m: 1.0662 - val_loss: 0.2094 - val_accuracy: 0.9250 - val_f1_m: 1.1578 - val_precision_m: 1.1289 - val_recall_m: 1.1885\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 1s 77ms/step - loss: 0.0412 - accuracy: 0.9912 - f1_m: 1.0392 - precision_m: 1.0113 - recall_m: 1.0687 - val_loss: 0.2596 - val_accuracy: 0.9000 - val_f1_m: 1.2007 - val_precision_m: 1.1843 - val_recall_m: 1.2179\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.0462 - accuracy: 0.9868 - f1_m: 1.0557 - precision_m: 1.0283 - recall_m: 1.0847 - val_loss: 0.2172 - val_accuracy: 0.9250 - val_f1_m: 1.1196 - val_precision_m: 1.1042 - val_recall_m: 1.1359\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 1s 86ms/step - loss: 0.0338 - accuracy: 0.9949 - f1_m: 1.0098 - precision_m: 0.9753 - recall_m: 1.0471 - val_loss: 0.1610 - val_accuracy: 0.9250 - val_f1_m: 1.1120 - val_precision_m: 1.1018 - val_recall_m: 1.1240\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 0.0251 - accuracy: 0.9934 - f1_m: 1.0175 - precision_m: 0.9878 - recall_m: 1.0493 - val_loss: 0.1862 - val_accuracy: 0.9438 - val_f1_m: 1.2084 - val_precision_m: 1.2012 - val_recall_m: 1.2173\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 1s 82ms/step - loss: 0.0284 - accuracy: 0.9901 - f1_m: 1.0115 - precision_m: 0.9840 - recall_m: 1.0410 - val_loss: 0.1857 - val_accuracy: 0.9438 - val_f1_m: 1.1320 - val_precision_m: 1.1057 - val_recall_m: 1.1598\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.0236 - accuracy: 0.9936 - f1_m: 1.0223 - precision_m: 0.9964 - recall_m: 1.0497 - val_loss: 0.2177 - val_accuracy: 0.9375 - val_f1_m: 1.1664 - val_precision_m: 1.1528 - val_recall_m: 1.1808\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 1s 84ms/step - loss: 0.0163 - accuracy: 0.9957 - f1_m: 1.0041 - precision_m: 0.9721 - recall_m: 1.0383 - val_loss: 0.1592 - val_accuracy: 0.9375 - val_f1_m: 1.1776 - val_precision_m: 1.1685 - val_recall_m: 1.1885\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 1s 77ms/step - loss: 0.0123 - accuracy: 0.9970 - f1_m: 0.9970 - precision_m: 0.9690 - recall_m: 1.0268 - val_loss: 0.1747 - val_accuracy: 0.9375 - val_f1_m: 1.1271 - val_precision_m: 1.1085 - val_recall_m: 1.1472\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.0137 - accuracy: 0.9953 - f1_m: 0.9863 - precision_m: 0.9518 - recall_m: 1.0238 - val_loss: 0.1479 - val_accuracy: 0.9438 - val_f1_m: 1.0859 - val_precision_m: 1.0586 - val_recall_m: 1.1149\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    model.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
