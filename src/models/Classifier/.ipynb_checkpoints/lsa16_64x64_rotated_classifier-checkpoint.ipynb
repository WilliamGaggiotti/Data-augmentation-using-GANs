{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nonprofit-justice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fluid-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "import handshape_datasets as hd\n",
    "from IPython import display\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import VGG16, VGG19\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Conv2D, LeakyReLU, Dropout, Flatten\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "attempted-navigator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "              tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "        \n",
    "print(tf.config.experimental.list_logical_devices('GPU'))\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-ivory",
   "metadata": {},
   "source": [
    "## Function to scale the images in the range of [-1 ,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "unknown-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_images(images):\n",
    "    return (images - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-paraguay",
   "metadata": {},
   "source": [
    "### hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "developing-repository",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "rotation_range = 20\n",
    "width_shift_range = 0.15\n",
    "height_shift_range = 0.15\n",
    "horizontal_flip = True\n",
    "vertical_flip = True\n",
    "shear_range = 0\n",
    "zoom_range = [0.8,1.0]\n",
    "brightness_range=[0.8,1.0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-parish",
   "metadata": {},
   "source": [
    "## Create train_generator and val_generator with and without data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "greatest-helping",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator sin data augmentation\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=normalize_images)\n",
    "\n",
    "#Generator con data augmentation\n",
    "train_datagen_aug = ImageDataGenerator(preprocessing_function=normalize_images,\n",
    "                                        horizontal_flip=horizontal_flip,\n",
    "                                        brightness_range=brightness_range,\n",
    "                                        zoom_range=zoom_range)\n",
    "\n",
    "#Generator de validacion\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=normalize_images)\n",
    "\n",
    "\n",
    "#Directorio de imagenes\n",
    "train_folderpath = '../../../datasets/lsa16_64x64_rotated/train'\n",
    "val_folderpath = '../../../datasets//lsa16_64x64_rotated/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "convinced-bracelet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10240 images belonging to 16 classes.\n",
      "Found 10240 images belonging to 16 classes.\n",
      "Found 2560 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_folderpath, # directorio de donde cargar las imagenes (train)\n",
    "    target_size=(64, 64),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse')\n",
    "\n",
    "train_generator_aug = train_datagen_aug.flow_from_directory(\n",
    "    train_folderpath, # directorio de donde cargar las imagenes (train)\n",
    "    target_size=(64, 64),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse')\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    val_folderpath, # directorio de donde cargar las imagenes (train)\n",
    "    target_size=(64, 64),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse')\n",
    "\n",
    "\n",
    "n_train = train_generator.samples\n",
    "n_train_aug = train_generator_aug.samples\n",
    "n_val = val_generator.samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-anniversary",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "spectacular-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same',input_shape=[64, 64, 3]))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(16, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "successful-horse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_32 (Conv2D)           (None, 32, 32, 64)        4864      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 16, 16, 128)       204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                524304    \n",
      "=================================================================\n",
      "Total params: 734,096\n",
      "Trainable params: 734,096\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model()\n",
    "model.summary()\n",
    "model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-cookie",
   "metadata": {},
   "source": [
    "## Training without data augmentaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "natural-questionnaire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 2.4849 - accuracy: 0.1951 - val_loss: 1.7819 - val_accuracy: 0.4090\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 1.4596 - accuracy: 0.5178 - val_loss: 1.1679 - val_accuracy: 0.6473\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.9488 - accuracy: 0.6915 - val_loss: 0.9571 - val_accuracy: 0.6824\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.6913 - accuracy: 0.7733 - val_loss: 0.7949 - val_accuracy: 0.7445\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.4995 - accuracy: 0.8404 - val_loss: 0.8120 - val_accuracy: 0.7512\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.5073 - accuracy: 0.8311 - val_loss: 0.8898 - val_accuracy: 0.7344\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.3661 - accuracy: 0.8717 - val_loss: 0.8497 - val_accuracy: 0.7613\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.3073 - accuracy: 0.8978 - val_loss: 0.8061 - val_accuracy: 0.7594\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.3310 - accuracy: 0.8844 - val_loss: 0.7785 - val_accuracy: 0.7770\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.2823 - accuracy: 0.9004 - val_loss: 0.9592 - val_accuracy: 0.7586\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.2649 - accuracy: 0.9092 - val_loss: 0.8970 - val_accuracy: 0.7809\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.2256 - accuracy: 0.9212 - val_loss: 0.9437 - val_accuracy: 0.7637\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.2437 - accuracy: 0.9149 - val_loss: 0.9649 - val_accuracy: 0.7691\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.2382 - accuracy: 0.9169 - val_loss: 0.8480 - val_accuracy: 0.8066\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.1772 - accuracy: 0.9403 - val_loss: 0.9409 - val_accuracy: 0.7852\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.1827 - accuracy: 0.9345 - val_loss: 1.0558 - val_accuracy: 0.7773\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 4s 49ms/step - loss: 0.2018 - accuracy: 0.9329 - val_loss: 1.0626 - val_accuracy: 0.7770\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.2159 - accuracy: 0.9207 - val_loss: 0.9387 - val_accuracy: 0.7895\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.1556 - accuracy: 0.9447 - val_loss: 0.9807 - val_accuracy: 0.7922\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 4s 48ms/step - loss: 0.1451 - accuracy: 0.9482 - val_loss: 1.0451 - val_accuracy: 0.7793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1df2dc2e20>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with tf.device('/CPU:0'):\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=n_train//batch_size,\n",
    "                    epochs=20,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=n_val//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-scottish",
   "metadata": {},
   "source": [
    "## Training with data augmentaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "existing-pittsburgh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "80/80 [==============================] - 14s 167ms/step - loss: 2.5590 - accuracy: 0.1577 - val_loss: 2.1571 - val_accuracy: 0.3133\n",
      "Epoch 2/20\n",
      "80/80 [==============================] - 13s 164ms/step - loss: 1.8041 - accuracy: 0.4006 - val_loss: 1.8253 - val_accuracy: 0.4484\n",
      "Epoch 3/20\n",
      "80/80 [==============================] - 14s 176ms/step - loss: 1.4282 - accuracy: 0.5315 - val_loss: 1.8119 - val_accuracy: 0.4512\n",
      "Epoch 4/20\n",
      "80/80 [==============================] - 13s 160ms/step - loss: 1.1929 - accuracy: 0.5988 - val_loss: 1.4890 - val_accuracy: 0.5465\n",
      "Epoch 5/20\n",
      "80/80 [==============================] - 13s 167ms/step - loss: 1.1135 - accuracy: 0.6190 - val_loss: 1.4840 - val_accuracy: 0.5391\n",
      "Epoch 6/20\n",
      "80/80 [==============================] - 13s 159ms/step - loss: 0.9852 - accuracy: 0.6720 - val_loss: 1.5189 - val_accuracy: 0.5309\n",
      "Epoch 7/20\n",
      "80/80 [==============================] - 13s 162ms/step - loss: 0.9539 - accuracy: 0.6805 - val_loss: 1.1745 - val_accuracy: 0.6246\n",
      "Epoch 8/20\n",
      "80/80 [==============================] - 13s 165ms/step - loss: 0.9216 - accuracy: 0.6877 - val_loss: 1.2435 - val_accuracy: 0.6082\n",
      "Epoch 9/20\n",
      "80/80 [==============================] - 13s 156ms/step - loss: 0.8968 - accuracy: 0.6965 - val_loss: 1.1745 - val_accuracy: 0.6578\n",
      "Epoch 10/20\n",
      "80/80 [==============================] - 13s 165ms/step - loss: 0.8327 - accuracy: 0.7176 - val_loss: 1.2904 - val_accuracy: 0.6187\n",
      "Epoch 11/20\n",
      "80/80 [==============================] - 13s 158ms/step - loss: 0.8180 - accuracy: 0.7231 - val_loss: 1.2663 - val_accuracy: 0.6418\n",
      "Epoch 12/20\n",
      "80/80 [==============================] - 14s 169ms/step - loss: 0.7700 - accuracy: 0.7413 - val_loss: 1.1286 - val_accuracy: 0.6687\n",
      "Epoch 13/20\n",
      "80/80 [==============================] - 13s 159ms/step - loss: 0.7550 - accuracy: 0.7539 - val_loss: 1.2188 - val_accuracy: 0.6445\n",
      "Epoch 14/20\n",
      "80/80 [==============================] - 13s 165ms/step - loss: 0.7120 - accuracy: 0.7643 - val_loss: 1.1180 - val_accuracy: 0.6684\n",
      "Epoch 15/20\n",
      "80/80 [==============================] - 13s 163ms/step - loss: 0.7031 - accuracy: 0.7627 - val_loss: 1.1310 - val_accuracy: 0.6629\n",
      "Epoch 16/20\n",
      "80/80 [==============================] - 13s 158ms/step - loss: 0.6960 - accuracy: 0.7674 - val_loss: 1.3023 - val_accuracy: 0.6156\n",
      "Epoch 17/20\n",
      "80/80 [==============================] - 14s 168ms/step - loss: 0.7159 - accuracy: 0.7615 - val_loss: 1.2188 - val_accuracy: 0.6676\n",
      "Epoch 18/20\n",
      "80/80 [==============================] - 13s 159ms/step - loss: 0.7075 - accuracy: 0.7642 - val_loss: 1.0192 - val_accuracy: 0.7086\n",
      "Epoch 19/20\n",
      "80/80 [==============================] - 12s 147ms/step - loss: 0.6510 - accuracy: 0.7753 - val_loss: 1.0851 - val_accuracy: 0.6859\n",
      "Epoch 20/20\n",
      "80/80 [==============================] - 12s 150ms/step - loss: 0.6333 - accuracy: 0.7875 - val_loss: 1.3759 - val_accuracy: 0.6293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1dc24f5c40>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with tf.device('/CPU:0'):\n",
    "model.fit_generator(train_generator_aug,\n",
    "                    steps_per_epoch=n_train_aug//batch_size,\n",
    "                    epochs=20,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=n_val//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-general",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
