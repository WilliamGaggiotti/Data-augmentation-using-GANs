{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import handshape_datasets as hd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import handshape_datasets as hd\n",
    "import numpy as np\n",
    "import os\n",
    "from ipynb.fs.full.FID_Pytorch import *\n",
    "torch.manual_seed(0) # Set for our testing purposes, please do not change!\n",
    "\n",
    "def show_tensor_images(image_tensor, num_images=16, size=(3, 32, 32), nrow=4, show=True, name='default'):\n",
    "    '''\n",
    "    Function for visualizing images: Given a tensor of images, number of images, and\n",
    "    size per image, plots and prints the images in an uniform grid.\n",
    "    '''\n",
    "    image_tensor = (image_tensor + 1) / 2\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=nrow)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    #plt.savefig('/home/willys/tesis/Data-augmentation-using-GANs/data_gen/CW-GAN/PugeaultASL_A/'+name)\n",
    "    if show:\n",
    "        plt.show()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-bedroom",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-video",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 70\n",
    "z_dim = 64\n",
    "display_step = 50\n",
    "batch_size = 128\n",
    "lr = 0.0002\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "c_lambda = 10\n",
    "crit_repeats = 3\n",
    "device = 'cuda'\n",
    "save_path = 'numpy_data/PugeaultASL_A/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-costs",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-peninsula",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim=10, im_chan=3, hidden_dim=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        # Build the neural network\n",
    "        self.gen = nn.Sequential(\n",
    "            self.make_gen_block(input_dim, hidden_dim * 8),\n",
    "            self.make_gen_block(hidden_dim * 8, hidden_dim * 4, kernel_size=4, stride=1),\n",
    "            self.make_gen_block(hidden_dim * 4, hidden_dim * 2),\n",
    "            self.make_gen_block(hidden_dim * 2, hidden_dim, stride=1),\n",
    "            self.make_gen_block(hidden_dim, im_chan, kernel_size=4, final_layer=True),\n",
    "        )\n",
    "\n",
    "\n",
    "    def make_gen_block(self, input_channels, output_channels, kernel_size=3, stride=2, final_layer=False):\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.Tanh(),\n",
    "            )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        x = noise.view(len(noise), self.input_dim, 1, 1)\n",
    "        return self.gen(x)\n",
    "\n",
    "def get_noise(n_samples, input_dim, device='cpu'):\n",
    "    return torch.randn(n_samples, input_dim, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-plumbing",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-green",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    " \n",
    "    def __init__(self, im_chan=3, hidden_dim=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            self.make_disc_block(im_chan, hidden_dim),\n",
    "            self.make_disc_block(hidden_dim, hidden_dim * 2),\n",
    "            self.make_disc_block(hidden_dim * 2, 1, final_layer=True),\n",
    "        )\n",
    "\n",
    "    def make_disc_block(self, input_channels, output_channels, kernel_size=4, stride=2, final_layer=False):\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(input_channels, output_channels, kernel_size, stride),\n",
    "            )\n",
    "\n",
    "    def forward(self, image):\n",
    "        disc_pred = self.disc(image)\n",
    "        return disc_pred.view(len(disc_pred), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-hanging",
   "metadata": {},
   "source": [
    "### One_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-greece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def get_one_hot_labels(labels, n_classes):\n",
    "    '''\n",
    "    Function for creating one-hot vectors for the labels, returns a tensor of shape (?, num_classes).\n",
    "    Parameters:\n",
    "        labels: tensor of labels from the dataloader, size (?)\n",
    "        n_classes: the total number of classes in the dataset, an integer scalar\n",
    "    '''\n",
    "    return F.one_hot(labels, num_classes= n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-physics",
   "metadata": {},
   "source": [
    "### Combine_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-hearts",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_vectors(x, y):\n",
    "    '''\n",
    "    Function for combining two vectors with shapes (n_samples, ?) and (n_samples, ?).\n",
    "    Parameters:\n",
    "      x: (n_samples, ?) the first vector. \n",
    "        In this assignment, this will be the noise vector of shape (n_samples, z_dim), \n",
    "        but you shouldn't need to know the second dimension's size.\n",
    "      y: (n_samples, ?) the second vector.\n",
    "        Once again, in this assignment this will be the one-hot class vector \n",
    "        with the shape (n_samples, n_classes), but you shouldn't assume this in your code.\n",
    "    '''\n",
    "    # Note: Make sure this function outputs a float no matter what inputs it receives\n",
    "    #### START CODE HERE ####\n",
    "    combined = torch.cat((x.float(),y.float()),1)\n",
    "    #### END CODE HERE ####\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-track",
   "metadata": {},
   "source": [
    "## Data Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-evans",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTupleDataset(data.Dataset):\n",
    "    def __init__(self, dataset, batch_size=128):\n",
    "        super(MyTupleDataset, self).__init__()\n",
    "        self.x = dataset[0]\n",
    "        self.y = dataset[1]\n",
    "        self.len = dataset[0].shape[0]\n",
    "        self.batch_size = batch_size\n",
    "        self.act_idx = 0\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        print(index)\n",
    "        if (index+128 <= self.len):\n",
    "            x = torch.Tensor(self.x[index:index+128,:,:,:])  # batch dim is handled by the data loader\n",
    "            y = torch.Tensor(self.y[index:index+128,]) \n",
    "        else:\n",
    "            x2 = torch.Tensor(self.x[index:self.len,:,:,:])  # batch dim is handled by the data loader\n",
    "            y2 = torch.Tensor(self.y[index:self.len,]) \n",
    "            \n",
    "        return x.permute(0,3, 1, 2), y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def netx(self):\n",
    "        if (self.act_idx+128 <= self.len):\n",
    "            x = torch.Tensor(self.x[self.act_idx:(self.act_idx+self.batch_size),:,:,:]) \n",
    "            y = torch.Tensor(self.y[self.act_idx:(self.act_idx+self.batch_size),])\n",
    "            self.act_idx += 128\n",
    "        else:\n",
    "            x = torch.Tensor(self.x[self.act_idx:self.len-1,:,:,:]) \n",
    "            y = torch.Tensor(self.y[self.act_idx:self.len-1,])\n",
    "            self.act_idx = self.len\n",
    "            \n",
    "        return x.permute(0,3, 1, 2), y\n",
    "   \n",
    "    def reset_index(self):\n",
    "        self.act_idx = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-prevention",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    data = hd.load('PugeaultASL_A')\n",
    "\n",
    "    good_min = 40\n",
    "    good_classes = []\n",
    "    n_unique = len(np.unique(data[1]['y']))\n",
    "    for i in range(n_unique):\n",
    "        images = data[0][np.equal(i, data[1]['y'])]\n",
    "        if len(images) >= good_min:\n",
    "            good_classes = good_classes + [i]\n",
    "\n",
    "    x = data[0][np.in1d(data[1]['y'], good_classes)]\n",
    "    img_shape = x[0].shape\n",
    "    print(img_shape)\n",
    "    y = data[1]['y'][np.in1d(data[1]['y'], good_classes)]\n",
    "    y_dict = dict(zip(np.unique(y), range(len(np.unique(y)))))\n",
    "    y = np.vectorize(y_dict.get)(y)\n",
    "    classes = np.unique(y)\n",
    "    n_classes = len(classes)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, train_size=0.8, test_size=0.2, stratify=y)\n",
    "\n",
    "    #Reduciendo dataset\n",
    "    reduce = 8\n",
    "    for i in range(n_classes):\n",
    "        images = x_train[np.equal(i, y_train)]\n",
    "        #x_reduce = x_reduce + images[0:(len(images)//2),:,:,:]\n",
    "        if i==0:\n",
    "            x_reduce = images[0:(len(images)//reduce),:,:,:]\n",
    "            y_reduce = np.ones((len(images)//reduce)) * i\n",
    "        else:\n",
    "            x_reduce = np.concatenate((x_reduce, images[0:(len(images)//reduce),:,:,:]), axis=0)\n",
    "            y_temp = np.ones((len(images)//reduce)) * i\n",
    "            y_reduce = np.concatenate((y_reduce, y_temp), axis=0)\n",
    "\n",
    "    print('x.shpae: {}, y.shape: {}'.format(x.shape, y.shape))\n",
    "    print('x_reduce.shpae: {}, y_reduce.shape: {}'.format(x_reduce.shape, y_reduce.shape))\n",
    "\n",
    "    #Desordeno el nuevo dataset\n",
    "    shuffler = np.random.permutation(x_reduce.shape[0])\n",
    "    x_reduce = x_reduce[shuffler]\n",
    "    y_reduce = y_reduce[shuffler]\n",
    "    print(\"dataset final shape: {}, y final:{}\".format(x_reduce.shape,y_reduce.shape))\n",
    "\n",
    "\n",
    "    train_size = x_train.shape[0]\n",
    "    test_size = x_test.shape[0]\n",
    "\n",
    "    return n_classes, x_reduce, y_reduce, x_test, y_test \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-clarity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_dimensions(z_dim, img_shape, n_classes):\n",
    "    \n",
    "    generator_input_dim = z_dim + n_classes\n",
    "    discriminator_im_chan = img_shape[2] + n_classes\n",
    "\n",
    "    return generator_input_dim, discriminator_im_chan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-baking",
   "metadata": {},
   "source": [
    "### Create Generator and Discriminator with optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-festival",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_g_and_d(z_dim, img_shape, n_classes, device='cuda', lr=0.0002, beta_1=0.5, beta2=0.999):\n",
    "    generator_input_dim, discriminator_im_chan = get_input_dimensions(z_dim, img_shape, n_classes)\n",
    "\n",
    "    gen = Generator(input_dim=generator_input_dim).to(device)\n",
    "    gen_opt = torch.optim.Adam(gen.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "    disc = Discriminator(im_chan=discriminator_im_chan).to(device)\n",
    "    disc_opt = torch.optim.Adam(disc.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "\n",
    "    def weights_init(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "            torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "            torch.nn.init.constant_(m.bias, 0)\n",
    "    gen = gen.apply(weights_init)\n",
    "    disc = disc.apply(weights_init)\n",
    "\n",
    "    return gen, gen_opt, disc, disc_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-milton",
   "metadata": {},
   "source": [
    "### Get gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient(crit, real, fake, epsilon):\n",
    "    '''\n",
    "    Return the gradient of the critic's scores with respect to mixes of real and fake images.\n",
    "    Parameters:\n",
    "        crit: the critic model\n",
    "        real: a batch of real images\n",
    "        fake: a batch of fake images\n",
    "        epsilon: a vector of the uniformly random proportions of real/fake per mixed image\n",
    "    Returns:\n",
    "        gradient: the gradient of the critic's scores, with respect to the mixed image\n",
    "    '''\n",
    "    mixed_images = real * epsilon + fake * (1 - epsilon)\n",
    "    mixed_scores = crit(mixed_images)\n",
    "    \n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=mixed_images,\n",
    "        outputs=mixed_scores,\n",
    "        \n",
    "        grad_outputs=torch.ones_like(mixed_scores), \n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-staff",
   "metadata": {},
   "source": [
    "### Gradient penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-interaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(gradient):\n",
    "    '''\n",
    "    Return the gradient penalty, given a gradient.\n",
    "    Given a batch of image gradients, you calculate the magnitude of each image's gradient\n",
    "    and penalize the mean quadratic distance of each magnitude to 1.\n",
    "    Parameters:\n",
    "        gradient: the gradient of the critic's scores, with respect to the mixed image\n",
    "    Returns:\n",
    "        penalty: the gradient penalty\n",
    "    '''\n",
    "    # Flatten the gradients so that each row captures one image\n",
    "    gradient = gradient.view(len(gradient), -1)\n",
    "\n",
    "    # Calculate the magnitude of every row\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    \n",
    "    # Penalize the mean squared distance of the gradient norms from 1\n",
    "    penalty = torch.mean((gradient_norm - 1)**2)\n",
    "    return penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-algebra",
   "metadata": {},
   "source": [
    "### Gen Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-ethics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gen_loss(crit_fake_pred):\n",
    "    '''\n",
    "    Return the loss of a generator given the critic's scores of the generator's fake images.\n",
    "    Parameters:\n",
    "        crit_fake_pred: the critic's scores of the fake images\n",
    "    Returns:\n",
    "        gen_loss: a scalar loss value for the current batch of the generator\n",
    "    '''\n",
    "    gen_loss = -1. * torch.mean(crit_fake_pred)\n",
    "    return gen_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-league",
   "metadata": {},
   "source": [
    "### Crit loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-people",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crit_loss(crit_fake_pred, crit_real_pred, gp, c_lambda):\n",
    "    '''\n",
    "    Return the loss of a critic given the critic's scores for fake and real images,\n",
    "    the gradient penalty, and gradient penalty weight.\n",
    "    Parameters:\n",
    "        crit_fake_pred: the critic's scores of the fake images\n",
    "        crit_real_pred: the critic's scores of the real images\n",
    "        gp: the unweighted gradient penalty\n",
    "        c_lambda: the current weight of the gradient penalty \n",
    "    Returns:\n",
    "        crit_loss: a scalar for the critic's loss, accounting for the relevant factors\n",
    "    '''\n",
    "    crit_loss = torch.mean(crit_fake_pred) - torch.mean(crit_real_pred) + c_lambda * gp\n",
    "    return crit_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-feeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(gen, gen_opt, disc, disc_opt, dataloader, n_classes, n_epochs=60,\n",
    "         device='cuda', crit_repeats=3):\n",
    "    import time\n",
    "    cur_step = 0\n",
    "    generator_losses = []\n",
    "    discriminator_losses = []\n",
    "\n",
    "    #UNIT TEST NOTE: Initializations needed for grading\n",
    "    noise_and_labels = False\n",
    "    fake = False\n",
    "\n",
    "    fake_image_and_labels = False\n",
    "    real_image_and_labels = False\n",
    "    disc_fake_pred = False\n",
    "    disc_real_pred = False\n",
    "    #dataloader = MyTupleDataset(dataset)\n",
    "    for epoch in range(n_epochs):\n",
    "        print(epoch)\n",
    "        # Dataloader returns the batches and the labels\n",
    "        #for real, labels in tqdm(dataloader):\n",
    "        dataloader.reset_index()\n",
    "        for i in range((dataloader.len//dataloader.batch_size)+1):\n",
    "            real, labels = dataloader.netx()\n",
    "            cur_batch_size = len(real)\n",
    "            # Flatten the batch of real images from the dataset\n",
    "            real = real.to(device)\n",
    "\n",
    "            mean_iteration_critic_loss = 0\n",
    "            for _ in range(crit_repeats):\n",
    "\n",
    "                one_hot_labels = get_one_hot_labels(labels.to(torch.int64).to(device), n_classes)\n",
    "                image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "                image_one_hot_labels = image_one_hot_labels.repeat(1, 1, 32, 32)\n",
    "\n",
    "                ### Update discriminator ###\n",
    "                # Zero out the discriminator gradients\n",
    "                disc_opt.zero_grad()\n",
    "                # Get noise corresponding to the current batch_size \n",
    "                fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
    "\n",
    "                noise_and_labels = combine_vectors(fake_noise, one_hot_labels)\n",
    "                fake = gen(noise_and_labels)\n",
    "               \n",
    "                # Make sure that enough images were generated\n",
    "                assert len(fake) == len(real)\n",
    "\n",
    "                fake_image_and_labels = combine_vectors(fake, image_one_hot_labels)\n",
    "                real_image_and_labels = combine_vectors(real, image_one_hot_labels)\n",
    "                disc_fake_pred = disc(fake_image_and_labels.detach())\n",
    "                disc_real_pred = disc(real_image_and_labels)\n",
    "\n",
    "                # Make sure that enough predictions were made\n",
    "                assert len(disc_real_pred) == len(real)\n",
    "                # Make sure that the inputs are different\n",
    "                assert torch.any(fake_image_and_labels != real_image_and_labels)\n",
    "\n",
    "                epsilon = torch.rand(len(real), 1, 1, 1, device=device, requires_grad=True)\n",
    "                gradient = get_gradient(disc,\n",
    "                                        real_image_and_labels,\n",
    "                                        fake_image_and_labels.detach(),\n",
    "                                        epsilon)\n",
    "                gp = gradient_penalty(gradient)\n",
    "                disc_loss = get_crit_loss(disc_fake_pred, disc_real_pred, gp, c_lambda)\n",
    "\n",
    "                # Keep track of the average critic loss in this batch\n",
    "                mean_iteration_critic_loss += disc_loss.item() / crit_repeats\n",
    "                # Update gradients\n",
    "                disc_loss.backward(retain_graph=True)\n",
    "                # Update optimizer\n",
    "                disc_opt.step() \n",
    "\n",
    "            # Keep track of the average discriminator loss\n",
    "            discriminator_losses += [mean_iteration_critic_loss]    \n",
    "\n",
    "            ### Update generator ###\n",
    "            # Zero out the generator gradients\n",
    "            gen_opt.zero_grad()\n",
    "\n",
    "            fake_image_and_labels = combine_vectors(fake, image_one_hot_labels)\n",
    "            # This will error if you didn't concatenate your labels to your image correctly\n",
    "            disc_fake_pred = disc(fake_image_and_labels)\n",
    "            gen_loss = get_gen_loss(disc_fake_pred)\n",
    "            gen_loss.backward()\n",
    "            gen_opt.step()\n",
    "\n",
    "            # Keep track of the generator losses\n",
    "            generator_losses += [gen_loss.item()]\n",
    "\n",
    "\n",
    "            if cur_step % display_step == 0 and cur_step > 0:\n",
    "                #print(\"FID: {}\".format(get_FID(real.cpu(), fake.cpu())))\n",
    "                #torch.save(gen.state_dict(), 'numpy_data/PugeaultASL_A/iteration_2/gen.state_dict_cur_step_{}'.format(cur_step))\n",
    "                gen_mean = sum(generator_losses[-display_step:]) / display_step\n",
    "                disc_mean = sum(discriminator_losses[-display_step:]) / display_step\n",
    "                print(f\"Step {cur_step}: Generator loss: {gen_mean}, discriminator loss: {disc_mean}\")\n",
    "                show_tensor_images(fake)\n",
    "                show_tensor_images(real)\n",
    "                step_bins = 20\n",
    "                x_axis = sorted([i * step_bins for i in range(len(generator_losses) // step_bins)] * step_bins)\n",
    "                num_examples = (len(generator_losses) // step_bins) * step_bins\n",
    "                plt.plot(\n",
    "                    range(num_examples // step_bins), \n",
    "                    torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                    label=\"Generator Loss\"\n",
    "                )\n",
    "                plt.plot(\n",
    "                    range(num_examples // step_bins), \n",
    "                    torch.Tensor(discriminator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                    label=\"Discriminator Loss\"\n",
    "                )\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "            \n",
    "            cur_step += 1\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "    return gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-probability",
   "metadata": {},
   "outputs": [],
   "source": [
    "36987412wG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-convert",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-induction",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(10):\n",
    "    n_classes, x_train, y_train, x_test, y_test = load_dataset()\n",
    "    img_shape = x_train[0].shape\n",
    "    print(img_shape)\n",
    "    \n",
    "    #Guardo el split de los datos originales\n",
    "    data_dir = os.path.join(save_path, 'iteration_{}/'.format(j))\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    np.save(data_dir+'x_train',x_train)\n",
    "    np.save(data_dir+'y_train',y_train)\n",
    "    np.save(data_dir+'x_test',x_test)\n",
    "    np.save(data_dir+'y_test',y_test)\n",
    "            \n",
    "    x_train = x_train.astype('float32')\n",
    "    x_train = (x_train - 127.5) / 127.5\n",
    "    dataloader = MyTupleDataset((x_train,y_train))\n",
    "\n",
    "    #creamos el generador y discriminador junto con sus opts y losses\n",
    "    gen, gen_opt, disc, disc_opt = create_g_and_d(z_dim, img_shape, n_classes, \n",
    "                                                  device, lr, beta_1, beta_2)\n",
    "\n",
    "    #realizamos una epoca de entrenamiento\n",
    "    gen = train(gen, gen_opt, disc, disc_opt, dataloader, n_classes, 380,\n",
    "                device, crit_repeats)\n",
    "\n",
    "    #Guardamos el generador entrenado\n",
    "    torch.save(gen.state_dict(), data_dir+'gen.state_dict')\n",
    "\n",
    "    #Mergeamos los datos reales con los generados\n",
    "    '''for i in range(n_classes):\n",
    "        one_hot_labels = get_one_hot_labels((torch.ones(3000) * i).to(torch.int64).to(device), n_classes)\n",
    "        fake_noise = get_noise(3000, z_dim, device=device)\n",
    "        noise_and_labels = combine_vectors(fake_noise, one_hot_labels)\n",
    "        fake = gen(noise_and_labels)\n",
    "        image_unflat = fake.detach().cpu()\n",
    "        final_images = image_unflat.permute(0,2, 3, 1).numpy()\n",
    "\n",
    "        x_train = np.concatenate((x_train, final_images), axis=0)\n",
    "        y_tmp = np.ones(3000,)* i\n",
    "        y_train = np.concatenate((y_train,y_tmp), axis=0)\n",
    "    \n",
    "    #Desordeno el nuevo dataset\n",
    "    shuffler = np.random.permutation(x_train.shape[0])\n",
    "    x_train = x_train[shuffler]\n",
    "    y_train = y_train[shuffler]\n",
    "    print(x_train.shape, y_train.shape) \n",
    "    #Guardamos los datos mergeados\n",
    "    np.save(data_dir+'x_train_aug',((x_train+1)/2)) #para volver a la escala original\n",
    "    np.save(data_dir+'y_train_aug',y_train)'''\n",
    "\n",
    "    #Liberamos memoria\n",
    "    del gen, gen_opt, disc, disc_opt, x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-stanford",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 24\n",
    "img_shape = (32, 32, 3)\n",
    "for j in range(1):\n",
    "    data_dir = os.path.join(save_path, 'iteration_{}/'.format(j+2))\n",
    "    print(\"save_path: {}\".format(data_dir))\n",
    "    #cargo x_train e y_train\n",
    "    x_train = np.load(data_dir+'x_train.npy')\n",
    "    y_train = np.load(data_dir+'y_train.npy')\n",
    "    print('x_train.shape, y_train.shape')\n",
    "    print(x_train.shape, y_train.shape) \n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        #cargo el generador\n",
    "        gen, _, _, _ = create_g_and_d(z_dim, img_shape, n_classes, device, lr, beta_1, beta_2)\n",
    "        gen.load_state_dict(torch.load(data_dir+'gen.state_dict_cur_step_10550'))\n",
    "        gen.eval()\n",
    "        \n",
    "        #creo imagenes falsas y las mergeo\n",
    "        one_hot_labels = get_one_hot_labels((torch.ones(64) * i).to(torch.int64).to(device), n_classes)\n",
    "        fake_noise = get_noise(64, z_dim, device=device)\n",
    "        noise_and_labels = combine_vectors(fake_noise, one_hot_labels)\n",
    "        fake = gen(noise_and_labels)\n",
    "        image_unflat = fake.detach().cpu()\n",
    "        final_images = image_unflat.permute(0,2, 3, 1).numpy()\n",
    "        final_images = final_images * 127.5 + 127.5\n",
    "        \n",
    "        x_train = np.concatenate((x_train, final_images), axis=0)\n",
    "        y_tmp = np.ones(64,)* i\n",
    "        y_train = np.concatenate((y_train,y_tmp), axis=0)\n",
    "        \n",
    "    #Desordeno el nuevo dataset\n",
    "    shuffler = np.random.permutation(x_train.shape[0])\n",
    "    x_train = x_train[shuffler]\n",
    "    y_train = y_train[shuffler]\n",
    "    print(\" dataset final shape: {}, y final:{}\".format(x_train.shape,y_train.shape))\n",
    "    \n",
    "    #Guardamos los datos mergeados\n",
    "    x_train = x_train.astype('uint8')\n",
    "    np.save(data_dir+'x_train_aug',x_train) #para volver a la escala original\n",
    "    np.save(data_dir+'y_train_aug',y_train)\n",
    "    \n",
    "    #limpiamos memoria\n",
    "    torch.cuda.empty_cache()\n",
    "    del x_train, y_train, gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-surprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "inception_model = torch.hub.load('pytorch/vision:v0.9.0', 'inception_v3', pretrained=True)\n",
    "inception_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_features_list = []\n",
    "real_features_list = []\n",
    "\n",
    "gen.eval()\n",
    "n_samples = 512 # The total number of samples\n",
    "batch_size = 4 # Samples per iteration\n",
    "\n",
    "\n",
    "\n",
    "cur_samples = 0\n",
    "x_train = np.load('numpy_data/iteration_20/x_train.npy')\n",
    "y_train = np.load('numpy_data/iteration_20/y_train.npy')\n",
    "dataloader = MyTupleDataset((x_train,y_train),512)\n",
    "real_samples, labels = dataloader.netx()\n",
    "real_samples = real_samples.detach().cpu()\n",
    "cur_batch_size = len(real_samples)\n",
    "\n",
    "one_hot_labels = get_one_hot_labels(labels.to(torch.int64).to(device), 24)\n",
    "fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
    "noise_and_labels = combine_vectors(fake_noise, one_hot_labels)\n",
    "fake = gen(noise_and_labels)\n",
    "\n",
    "FID = get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-zoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.FID_Pytorch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_samples = torch.from_numpy(np.load('numpy_data/iteration_20/x_train.npy').astype('float32'))\n",
    "fake_samples = torch.from_numpy(np.load('numpy_data/iteration_20/x_train_fake.npy').astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-venezuela",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_samples = (real_samples - 127.5) / 127.5\n",
    "fake_samples = (fake_samples - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "FID = get_FID(real_samples[0:512,:,:,:], fake_samples[0:512,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-income",
   "metadata": {},
   "outputs": [],
   "source": [
    " data = hd.load('PugeaultASL_A')\n",
    "\n",
    "good_min = 40\n",
    "good_classes = []\n",
    "n_unique = len(np.unique(data[1]['y']))\n",
    "for i in range(n_unique):\n",
    "    images = data[0][np.equal(i, data[1]['y'])]\n",
    "    if len(images) >= good_min:\n",
    "        good_classes = good_classes + [i]\n",
    "\n",
    "x = data[0][np.in1d(data[1]['y'], good_classes)]\n",
    "img_shape = x[0].shape\n",
    "print(img_shape)\n",
    "y = data[1]['y'][np.in1d(data[1]['y'], good_classes)]\n",
    "y_dict = dict(zip(np.unique(y), range(len(np.unique(y)))))\n",
    "y = np.vectorize(y_dict.get)(y)\n",
    "n_classes = len(classes)\n",
    "\n",
    "#Reduciendo dataset\n",
    "for i in range(n_classes):\n",
    "    images = x[np.equal(i, y)]\n",
    "    #x_reduce = x_reduce + images[0:(len(images)//2),:,:,:]\n",
    "    if i==0:\n",
    "        x_reduce = images[0:(len(images)//2),:,:,:]\n",
    "        y_reduce = np.ones((len(images)//2)) * i\n",
    "    else:\n",
    "        x_reduce = np.concatenate((x_reduce, images[0:(len(images)//2),:,:,:]), axis=0)\n",
    "        y_temp = np.ones((len(images)//2)) * i\n",
    "        y_reduce = np.concatenate((y_reduce, y_temp), axis=0)\n",
    "        \n",
    "print('x.shpae: {}, y.shape: {}'.format(x.shape, y.shape))\n",
    "print('x_reduce.shpae: {}, y_reduce.shape: {}'.format(x_reduce.shape, y_reduce.shape))\n",
    "\n",
    "#Desordeno el nuevo dataset\n",
    "shuffler = np.random.permutation(x_reduce.shape[0])\n",
    "x_reduce = x_reduce[shuffler]\n",
    "y_reduce = y_reduce[shuffler]\n",
    "print(\"dataset final shape: {}, y final:{}\".format(x_reduce.shape,y_reduce.shape))\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_reduce, y_reduce, train_size=0.8, test_size=0.2, stratify=y_reduce)\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "#n_classes = len(classes)\n",
    "train_size = x_train.shape[0]\n",
    "test_size = x_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-enough",
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.in1d(data[1]['y'], good_classes)][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_reduce = np.array([32,32,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_reduce.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-sterling",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_reduce_aug = np.load('numpy_data/PugeaultASL_A/iteration_2/x_train_aug.npy')\n",
    "x_test = np.load('numpy_data/PugeaultASL_A/iteration_1/x_test.npy')\n",
    "\n",
    "x_reduce_aug = (x_reduce_aug.astype('float32') -127.5 ) / 127.5\n",
    "x_test = (x_test.astype('float32') -127.5 ) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-moses",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_FID(torch.from_numpy(x_test[0:512]),torch.from_numpy(x_reduce_aug[0:512]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-official",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
